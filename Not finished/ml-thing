
ok, let's start from some intro: groceristar have a one template. with shopping list items: like milk, beer, vodka, etc

since few weeks (as very less time with active job)
can i see that template

and i think that adding another few templates will add some value to my projects

sure you can

so, i find at least 200 links with different shoplist templates

template is in text file or excel file?

biggest trouble is how to get data from some other sites and convert it into proper javascript array.
it can be text, it can be image, etc
it's hard to create a regular expression, etc


it was first ML-like topic
another idea was to teach model to convert measurements

because it's very tricky to have like teaspoon, lb, ounce in one place
glass/spoons image in your medium link?


but measurement stuff is a long-shot
not very ready right now. just my research
so i propose to start from grocery lists

hold on will find ultimate template
http://www.grocerylists.org/ultimatest/
grab it from there
i convert it by hands into this files: https://github.com/GroceriStar/groceristar/tree/master/bin/grocery


scrappy tutorial - maybe it'll be a good thing

ok it helps to import data from websites/link
and scrap it

no it;s not my site. but current version of my project is ugly too
but right now i have designers in team, so...

if you are scraping someone's site, did you get permission from original author/website?
or not needed?

btw, this excel file is imported into my database - so you don't need to convert it - not sure if this is clear

i contacted main owner of this website - he's not replying. still waiting on fb invite
and i'm put in thngs at credit. don't want to be a bad person

http://www.grocerylists.org/wp-content/uploads/2013/01/grocerylistsDOTorg_Editable_v3_4.pdf
https://github.com/GroceriStar/groceristar/blob/master/credits.md


and when i start to form a list of 200 links - i contacted one website owner and tell him that maybe i'm stealing their data and ask if they want to figure this out. they star a conversation and then go away. 

i plan to have a cross link for each website that we're using - it also will be good for seo

no, there excel download file

you can combine ingredients into grocery lists


so, i find at least 200 links with different shoplist templates" instead of creating more template, isnt it possible to add items in existing template?

how templates are seggregated?

which 200 links you are talking about?

cann you share those with me?
https://github.com/GroceriStar/groceristar/issues/417

it's possible to add items into template
but people are lazy, i assume

it's not a task for you
but maybe it'll helps

let me complete that task
guide me how to compleete it
so that i can learn by work
ok

open a part1 subtask
and start from it

https://github.com/GroceriStar/groceristar/issues/418

i am here
i assume first result of your work will be excel-like file with data from that links

so this links are samples
you need to review them and grab data that we need
right now we need only departments and ingredients

www.allyou.com/food/one-list-five-meals/meal-planner-hearty-dish

i opened first link
what to do next?
what is department?
department is food category
so milk have department dairy



"Page Not Found"
for this case it's easy
you need to move that data into excel format
if link dont have information that we need - you should specify that in comments
at github taks
can you check comment?
and reword if needed?
do you mean right now or later?
now
yes i get a notification

do you want me to reply ?
i want you to check my comment,
is it ok?
for now is perfect
do you need information/comment in that way?
ok

i mean i dont have any plan at this moment

but I see that at least i can add numbers to the links and this will help us to understand each other
https://www.vegan-nutritionista.com/vegan-grocery-list.html

this one is looking for some money
should i specify same in comment?
yes numbering system is needed
yeah

or one should at least comment inline.
let me number it

there no rules right now - everything is evolving when we're talking with you
how to number it
that is fine
i like random people like you
they are more creative, open and honest

so we'll find a way how to get to result
so maybe - before we'll go into scrapping or ml you should just open that links and form some sort of plan

you had said 200 links, rightnow list is around 10 to 15 only

maybe it'll be better to have an excel file with "link", "status" headers
yeah, this is why i call it part#1

hmm

let me check other parts
ok found all links in other parts
but what is your plan, if there is downloadable template whcih needs money to download?
are you ready to pay them?

and i think i didnt move all links from my pc into github issues
no, i'm not ready to pay. because i have 0 in my account

so you are focussing only on free content now a days
if we don't have a free template - we skip it and move to the next option
right?
ok

and maybe later i'll contact website owner - we partner and he/she give me that list for free
do you have plan what if there are multiple similar recipes?
where

how to remove/prioritize
at https://github.com/ChickenKyiv

not get your question
let us sayi added recipe X
you added recipe X1
both recipes produce item # Y

one is good another recipe may not be good enough
or may be duplicated
by item # Y you mean ingredient?


nope
output product
still not clear

ok forget it
we may discuss it later
tell me what is next thing i should do now

what is yoru plan for me?
what should i start?
create an issue on github and explain it there. so we don't lose it. i care about any improvement
ok
later

you'll forget it - i can bet on it
do you want to see my to do list?
it is too much dump
wil i be scared?
yes of course

how much items you have on it?
many different things

unorganized way
i store at least 5000 links in my browser and i really need them
ok, about task
nic
e

what do you think we can do with this links?
will you be interested to help me with them?
because sometimes i think i should do them by my hands
but it's really dumb

first of all there should be provision that there should not be any duplicate links
if you are really interested to collect links for your project, you (we) should create a web crawler.
but
source are different

so yo'll need to create a new rule for each website
and content are different too
a web crawler can work automatically

as you know - there no rules about how to wrap that stuff in html
i think so
i'm ok with webcrawler if you can do it

i can try once scrapy tutorial is finished

so in total 2 crawlers
1) to collect links
2) to collect inforation from those links

ok second item may not be called a crawler instead it may be called as scraper
ok, so this will be our plan i like it
i'll create a separate repository for you - because this repo is messy
maybe later i'll clean it up






i mean a lot of data that i have and know - it's open to use
but most of them are in our slack workplace - i can add you if you want



it'll be cool if scrapper will works
yes it is alwayz fun to see robots in action



++++++++++++++++++++++++++++


about ML
let me explain how i came to this idea

so basically, my idea about adding ML to groceristar was simple
right now we have only one grocery list template
and i grab and import in by hands

few days ago i find at least 100-200 samples of templates - that i want to add

and i think that copy-pasting it by hands - really stupid idea

I am sorry but how does ML helps in adding template..

first stage is about to grab data
and i'm not a pro at ML so if this possible to use something more intelligent that just a web scrapper - it'll be timesaver
when we grab "ingredients/shopping list items" we need to add a category(Department) to each item
so if we have milk or cheese - we add dairy
and here ML can be beneficial

some of that templates(back to 200 links) are images - so we can use OCR

other thing is about measurements
like if i add olive oil - i don't need options like kilograms, right. just lliter* or ml
or if i add butter - i didn't use teaspoons - only grams or kilograms
Ok I got it we need to tokenize things.. and segregate things..
maybe - i'm not a ML pro, so you'll need to teach me
i mean my idea can be changed in order to get a result

Frankly I am not a pro too .. I am learning through projects. .

understand - so this can be a win-win situation

so you think we cannot grab data from that 200 links
imean without copy-paste

Ok let me explore.. can you send me one link and tell me the goal want to achieve.. I will let you know by tomorrow the  what could be our next step..

sure. but content is different - so it cannot be a simple regEx solution

btw, i'm ok to grab that data by hands, it's not a first time for me
it's just take a lot of time

Yes I got it .. we never know when will be the end for it .. it seems interesting to me .. I will definitely explore

End meaning we might get more template in future
bottom i store links at separated tasks: https://github.com/atherdon/groceristar/issues/417

i also trying to categorize links at excel file.  split it like - diets, images, allergies. but maybe for now it's not important
and this is template that i convert: http://www.grocerylists.org/wp-content/uploads/2013/01/grocerylistsDOTorg_Deluxe_v3_3.pdf

I have checked few links .. we can get list of items from text but for images .. I need to explore things ..
i think we have a lot of libraries that goes OCR
for converting images to text
Ok I will check it out..

ok, take your time and thanks for chatting with me - appreciate that
Thanks for your time too ðŸ™‚
have a nice day/evening
Have a nice day
FEB 2ND, 3:16PM

Hi Arthur, it seems we can do Ocr with pytesseract package, I am getting an error while performing the analysis on a sample image.. I will try to resolve it and let you know the result

FEB 2ND, 7:34PM
ok, btw if you'll need more data(i/e/ images) in order to test it - tel me
and can i create a new repo in order to store your code and manage our development process? maybe also later we'll be able to extend team that works on your code
will classify image only links in order to help you
btw, use me in any cases that i can help

FEB 3RD, 7:18AM
Sure I will let you know if I need your help..
what is your github username btw?
Once I have a complete code I will let you know we can keep the code then
ok not a problem - just trying to keep my hand on the track with interns, but you not a junior, so it's good for me

And i was thinked that we'll opensource it, maybe someone else will be able to use too


FEB 4TH, 6:34PM
Hi Arthur... I was able to solve the bug and was able to read the initial grocery list you have used to make the Groceristar but it is failing for images with very small font as they are indistinguishable for it.. I am trying to improve  accuracy by different methods (opencv thresholds) etc.. will let you know if there is any improvement .. fyi ignore if you already know it.. there is a image scrapper python script which helps to scrap images for a given URL..


FEB 5TH, 11:34AM
Hi Arthur, Can you send me few links which are most important for you .. I will try to use other software to improve the accuracy of text recognition.. my initial idea was to scrape through all websites but it seems the images are quite different from one another...


FEB 7TH, 10:24AM
Hi Arthur..

FEB 16TH, 11:50AM
hi Ravi, sorry i was offline 10 days. will reply to you soon

FEB 24TH, 11:24PM
sorrt for not getting back for a while....

looking for thngs that you need right now

MAR 1ST, 10:51PM
can you check this issue for images/samples for your algo: https://github.com/GroceriStar/groceristar/issues/447?
and sorry again for this delay.
i tried a different layouts, fonts - in order to make tests better

5:00AM
Hi Ravi, just follow up you. want to know if you still interested to work together. if no, can you please share with me your code repository - i'll clone it and maybe someone will be able to improve it and we'll include it to our working project


